rascunho icposter


abstract:

Jump Markov linear systems (JMLS) are linear systems whose parameters evolve with time according to a finite state Markov chain. In this paper, our aim is to recursively compute optimal state estimates for this class of systems. We present efficient simulation-based algorithms called particle filters to solve the optimal filtering problem as well as the optimal fixed-lag smoothing problem. Our algorithms combine sequential importance sampling, a selection scheme, and Markov chain Monte Carlo methods. They use several variance reduction methods to make the most of the statistical structure of JMLS. Computer simulations are carried out to evaluate the performance of the proposed algorithms. The problems of on-line deconvolution of impulsive processes and of tracking a maneuvering target are considered. It is shown that our algorithms outperform the current methods

Sistemas sujeitos a saltos markovianos são sistemas lineares cujos parâmetros se relacionan com o tempo de acordo com uma cadeia de markov em espaço finito. Neste artigo, nosso objetivo é recursivamente cumputar o estado otimo estimado para essa classe de sistema. Nos apresentamos simulações eficientes baseadas em algoritmos chamados filtros de particulas para resolver o problema do filtro otimo, tanto quanto o otimo fixo suavizado. 

Existe atualmente uma vasta literatura dedicada ao estudo de sistemas su-
jeitos a varia ̧c ̃oes abruptas em sua estrutura. Tal fenˆomeno pode decorrer,
por exemplo, de falhas em sistemas de comunica ̧c a  ̃ o, de mudan ̧cas no ponto
de opera ̧c a  ̃ o de sistemas n ̃ao-lineares, da quebra de componentes em proces-
sos industriais, do rompimento de cabos em sistemas el ́etricos, ou de fatores
ambientais diversos. Devido `a crescente complexidade das aplica ̧c o  ̃ es mo-
dernas, impulsionadas em grande parte pelos avan ̧cos em telecomunica ̧c o  ̃ es e
em computa ̧c ̃ao distribu ́ıda, o estudo de tais sistemas  ́e atualmente uma das
principais tendˆencias em pesquisa na teoria de sistemas e controle. Uma am-
pla discuss ̃ao no assunto pode ser encontrada nos livros [7–9,12,13,20,21,30],
por exemplo.
A despeito do consider ́avel grau de maturidade te ́orica alcan ̧cada no es-
tudo de sistemas dinˆamicos estoc ́asticos nas u
 ́ ltimas d ́ecadas, sabe-se atual-
mente que o escopo de problemas de interesse pr ́atico que s ̃ao pass ́ıveis de
tratamento computacional eficiente  ́e limitado. Dentre algumas das princi-
pais dificuldades encontradas na literatura, pode-se destacar n ̃ao-convexidade
[4, 16, 35], mal da dimensionalidade [1, 10, 27, 33], a falta de um modelo pre-
ciso [6,34], ou aspectos intrinsecamente relacionados a complexidade compu-
tacional em geral [3].
Nestas situa ̧c ̃oes, muitas vezes  ́e conveniente abordar o problema atrav ́es
de simula ̧c a  ̃ o estoc ́astica. Uma amostra dos trabalhos dedicados a este tipo
de abordagem na teoria de sistemas e controle pode ser encontrada em: [11],
que tratou a filtragem de part ́ıculas de sistemas com saltos Markovianos; [22],
no contexto de processos de decis ̃ao Markovianos; [14], que propˆos uma arqui-
tetura randomizada de planejamento de curso para sistemas dinˆamicos com
presen ̧ca de obst ́aculos; e [17–19], que, atrav ́es de cadeias de Markov, trata-
ram de aspectos descentralizados envolvendo o algoritmo PageRank (que tem
um papel fundamental nas buscas realizadas pelo portal Google). Uma abor-
dagem de particular interesse para o presente projeto foi proposta em [23–25],
envolvendo o controle estoc ́astico de um processo de Markov sujeito a saltos,
atrav ́es de uma metodologia inspirada em quimiotaxia (locomo ̧c ̃ao de c ́elulas
ou microorganismos com respeito a um gradiente qu ́ımico). Os resultados
obtidos em [23–25] sugerem uma poderosa alternativa para o controle de sis-
temas rob ́oticos multi-agentes, atrav ́es de uma t ́ecnica que guarda bastante
similaridade com m ́etodos de simula ̧c ̃ao estoc ́astica do tipo Markov Chain
Monte Carlo.

Este projeto de pesquisa se prop ̃oe a investigar as alternativas existentes
na literatura dedicada `a simula ̧c a  ̃ o de sistemas estoc ́asticos sujeitos a saltos
Markovianos, com especial aten ̧c ̃ao para m ́etodos baseados em cadeias de
Markov (tais como Markov Chain Monte Carlo ou Simulated Annealing, por
exemplo [5,15,26]), e para aplica ̧c o  ̃ es em rob ́otica e em problemas de consenso
de sistemas de controle multi-agentes (tais como aqueles estudados em [17–
19, 23–25], por exemplo).




 [17–19], que, atrav ́es de cadeias de Markov, trata-
ram de aspectos descentralizados envolvendo o algoritmo PageRank (que tem
um papel fundamental nas buscas realizadas pelo portal Google)

Os resultados
obtidos em [23–25] sugerem uma poderosa alternativa para o controle de sis-
temas rob ́oticos multi-agentes, atrav ́es de uma t ́ecnica que guarda bastante
similaridade com m ́etodos de simula ̧c ̃ao estoc ́astica do tipo Markov Chain
Monte Carlo.

Samuelson’s multiplier–accelerator model, published in 1939 [196], is possibly
the first dynamic model based on economic theories to address the problem
of income determination and the business cycle.
A very interesting application of MJLS to economic modeling employ-
ing the multiplier–accelerator model is presented in [28] and here is slightly
adapted to fit our framework.

Abstract:
******

******

Introdução:
******
motivação
aplicações
dificuldades em simulações

Os sistemas sujeitos a saltos markovianos tratan-se de uma classe de sistemas lineares, cujos parâmetros se relacionam com o tempo e evoluem de acordo com uma cadeia de markov em um espaço finito. Exite uma vasta literatura dedicada ao estudo desses sistemas, que sofrem variações abruptas em sua estrutura. Essas variações podem surgir, i.e. por falhas de comunicação entre agentes [AM].    
******

Modelo Matemático:
******

******

Aplicação:
******

******

Perspectivas Futuras:
******
Neste projeto objetiva-se pesquisar alternativas em controle e simulação de sistemas estocásticos sujeitos a saltos markovianos. E buscar aplicação em problemas de consenso de sistemas multi-agentes, por isso, uma certa atenção será dada ao método de Markov Chain Monte Carlo e Simulated Annealing, métodos estes baseados em cadeias de Markov.
******

